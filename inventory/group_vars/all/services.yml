---
# Single Source of Truth for Infrastructure Services
# This file defines currently deployed and accessible services

infrastructure_services:

  # ==================================================================
  # DEPLOYED & WORKING - Services that are running and accessible
  # ==================================================================

  - name: Links Portal
    slug: links
    icon: "ğŸ”—"
    description: Service directory and landing page
    subdomain: links
    status: deployed_working
    note: "Public landing page, no authentication"

  - name: Jitsi Meet
    slug: meet
    icon: "ğŸ“¹"
    description: Video conferencing service
    subdomain: meet
    status: deployed_working
    note: "Directly accessible, uses own authentication"

  - name: Nextcloud
    slug: cloud
    icon: "â˜ï¸"
    description: Cloud file storage and synchronization
    subdomain: cloud
    status: deployed_working
    note: "Directly accessible, uses own authentication"

  - name: Jellyfin
    slug: media
    icon: "ğŸ¬"
    description: Media streaming and management
    subdomain: media
    status: deployed_working
    note: "Directly accessible, uses own authentication"

  - name: qBittorrent
    slug: torrent
    icon: "â¬‡ï¸"
    description: BitTorrent client
    subdomain: torrent
    status: deployed_working
    note: "Directly accessible, uses own authentication"

  - name: Zipline
    slug: zipline
    icon: "ğŸ“"
    description: File sharing service
    subdomain: zipline
    status: deployed_working
    note: "Directly accessible, uses own authentication"

  - name: Webtop
    slug: webtop
    icon: "ğŸ’»"
    description: Browser-based desktop environment
    subdomain: webtop
    status: deployed_working
    note: "Protected by OAuth2-Proxy (GitLab SSO)"

  - name: Mailhog
    slug: mail
    icon: "ğŸ“§"
    description: Email testing tool
    subdomain: mail
    status: deployed_working
    note: "Protected by OAuth2-Proxy (GitLab SSO)"

# Infrastructure services (not exposed externally)
infrastructure_services_internal:
  - name: Ollama LLM
    type: vm
    vmid: 201
    icon: "ğŸ¤–"
    description: Ollama LLM inference server
    network: vmbr3 (172.31.31.0/24)
    ip: 172.31.31.201/24
    status: deployed_working
    note: "Running Ubuntu 24.04 with Ollama v0.13.0, accessible from Proxmox host, tested with qwen2.5:0.5b model"
